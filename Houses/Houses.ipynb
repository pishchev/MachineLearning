{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepairing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteId(ds):\n",
    "    return ds.drop(columns='Id')\n",
    "\n",
    "def deleteNaN(train_ds, test_ds, critval):\n",
    "    fullsize = train_ds.shape[0]\n",
    "    new_train = train_ds.copy()\n",
    "    new_test = test_ds.copy()\n",
    "    for feature in new_train.columns:\n",
    "        nulls = new_train[feature].isnull().sum()\n",
    "        percent = nulls / fullsize\n",
    "        if (percent > critval):\n",
    "            #print(f'Feature {feature} was removed: \\nNaNs {(percent * 100):.2f}%')\n",
    "            new_train = new_train.drop(columns=feature)\n",
    "            new_test = new_test.drop(columns=feature)\n",
    "    return new_train, new_test\n",
    "\n",
    "def fillNaN(train_ds, test_ds, method='ffill'):\n",
    "    new_train = train_ds.copy()\n",
    "    new_test = test_ds.copy()\n",
    "    new_train = new_train.fillna(method=method)\n",
    "    new_test = new_test.fillna(method=method)\n",
    "    return new_train, new_test\n",
    "\n",
    "def convertToNumeric(train_ds, test_ds):\n",
    "    new_train = train_ds.copy()\n",
    "    new_test = test_ds.copy()\n",
    "    LE = LabelEncoder()\n",
    "    for feature in new_train.columns[:-1]:\n",
    "        if (new_train[feature].dtype == 'object'):\n",
    "            new_train[feature] = LE.fit_transform(new_train[feature])\n",
    "            new_test[feature] = LE.fit_transform(new_test[feature])\n",
    "    return new_train, new_test\n",
    "\n",
    "def check_error(preds, gt):\n",
    "    print('Absolute Error:', metrics.mean_absolute_error(preds, gt))\n",
    "    print('Squared Error:', metrics.mean_squared_error(preds, gt))\n",
    "    print('Squared Log Error:', metrics.mean_squared_log_error(preds, gt))\n",
    "\n",
    "def deleteCorrelation(train_ds, test_ds, threshold):\n",
    "    corr_matrix = train_ds.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    new_train = train_ds.copy()\n",
    "    new_test = test_ds.copy()\n",
    "    for feature in to_drop:\n",
    "        new_train = new_train.drop(columns=feature)\n",
    "        new_test = new_test.drop(columns=feature)\n",
    "\n",
    "    return new_train, new_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "train = deleteId(train) \n",
    "train, test = deleteNaN(train, test ,critval=0.4)   \n",
    "train, test = fillNaN(train, test) \n",
    "train, test = convertToNumeric(train, test) \n",
    "train, test = deleteCorrelation(train, test, threshold=0.8) \n",
    "\n",
    "y_train = np.log1p(train['SalePrice'].values)\n",
    "x_train = train.drop(columns='SalePrice').values\n",
    "x_super_test = test.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=98987)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 20)\n",
    "X_train = pca.fit_transform(X_train, y_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'squared_error', 'max_depth': 500, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'criterion':('squared_error', 'absolute_error', 'poisson'), \n",
    "    'max_depth': (100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, None),\n",
    "    'max_features':('auto', 'sqrt', 'log2')}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "gs_model = GridSearchCV(model, parameters)\n",
    "gs_model.fit(X_train[:300], y_train[:300])\n",
    "print(f\"Best parameters: {gs_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error: 0.14882760244251803\n",
      "Squared Error: 0.04738547632888391\n",
      "Squared Log Error: 0.0002910504625439407\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(**gs_model.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "check_error(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.4, 'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\": (0.05, 0.10, 0.15, 0.2),\n",
    "    \"max_depth\": [ 3, 4, 5, 6, 8],\n",
    "    \"min_child_weight\": [ 1, 2, 3, 4, 5, 7],\n",
    "    \"gamma\":[ 0.0, 0.1, 0.2],\n",
    "    \"colsample_bytree\":[ 0.3, 0.4, 0.5, 0.6, 0.7]}\n",
    "\n",
    "model = XGBRegressor()\n",
    "gs_model = GridSearchCV(model, parameters)\n",
    "gs_model.fit(X_train[:300], y_train[:300])\n",
    "print(f\"Best parameters: {gs_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error: 0.14653263485496532\n",
      "Squared Error: 0.042272804397422155\n",
      "Squared Log Error: 0.00026190108064463657\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(**gs_model.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "check_error(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'depth': 6, 'l2_leaf_reg': 1, 'learning_rate': 0.1, 'logging_level': 'Silent'}\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor()\n",
    "\n",
    "parameters = {\n",
    "        'learning_rate': [0.03, 0.1],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "        'logging_level': ['Silent']}\n",
    "\n",
    "gs_model = GridSearchCV(model, parameters)\n",
    "gs_model.fit(X_train[:300], y_train[:300])\n",
    "print(f\"Best parameters: {gs_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error: 0.13285845648348427\n",
      "Squared Error: 0.03831134038325577\n",
      "Squared Log Error: 0.00023828232203326397\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(**gs_model.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "check_error(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 200, 'num_leaves': 7}\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "parameters = {\n",
    "    'num_leaves': [i for i in range(3,30)],\n",
    "    'learning_rate': [0.1, 0.07, 0.05, 0.03, 0.01, 0.007, 0.005, 0.003, 0.001],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'n_estimators': [50, 100, 200, 250, 300, 400, 500],}\n",
    "\n",
    "gs_model = GridSearchCV(model, parameters)\n",
    "gs_model.fit(X_train[:300], y_train[:300])\n",
    "print(f\"Best parameters: {gs_model.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error: 0.14555054351248695\n",
      "Squared Error: 0.04647049885139293\n",
      "Squared Log Error: 0.0002858500424465845\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor(**gs_model.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "check_error(model.predict(X_test), y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
